# -*- coding: utf-8 -*-
"""CS471assignment4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vr6EM-phtz20d0da77lh0diBy2nK_jOH
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt # data visualization
import seaborn as sns # statistical data visualization
# %matplotlib inline

from sklearn.datasets import load_iris

# Call the load_iris function to get the dataset
iris_data = load_iris()

# Create a DataFrame from the data
df = pd.DataFrame(data=iris_data.data, columns=iris_data.feature_names)

# Display the dimensions of the DataFrame
df.shape

# Display the first few rows of the DataFrame
df.head()

# View summary of data
df.info()

# Add the target variable to the DataFrame
df['species'] = iris_data.target

# Map the target values to their corresponding names
df['species'] = df['species'].map({0: iris_data.target_names[0], 1: iris_data.target_names[1], 2: iris_data.target_names[2]})

# Display frequency counts of the 'species' column
display(df['species'].value_counts())

import matplotlib.pyplot as plt
df.hist(bins=50, figsize=(12, 8))
plt.show()

from sklearn.model_selection import train_test_split

# Separate features (X) and target (y)
X = df.drop('species', axis=1)
y = df['species']

# Split data into training and the rest (validation + test)
X_train, X_rem, y_train, y_rem = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# Split the rest into validation and test sets
X_val, X_test, y_val, y_test = train_test_split(X_rem, y_rem, test_size=0.5, random_state=42, stratify=y_rem)

# Display the shapes of the resulting sets
print("Training set shape (X_train, y_train):", X_train.shape, y_train.shape)
print("Validation set shape (X_val, y_val):", X_val.shape, y_val.shape)
print("Testing set shape (X_test, y_test):", X_test.shape, y_test.shape)

from sklearn.tree import DecisionTreeClassifier

# Create a Decision Tree Classifier object with entropy criterion and max_depth
dt_classifier = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=42)

# Fit the model to the training data
dt_classifier.fit(X_train, y_train)

print("Decision Tree Classifier fitted successfully with entropy criterion and max_depth=3.")

# Define a range of values for max_depth to explore
max_depth_values = range(1, 11)

# Display the defined range of values
print("Max depth values to explore:", list(max_depth_values))

from sklearn.metrics import accuracy_score

# Create an empty list to store the accuracy scores
accuracy_scores = []

# Loop through the max_depth values
for max_depth in max_depth_values:
    # Instantiate a DecisionTreeClassifier
    dt_classifier = DecisionTreeClassifier(criterion='entropy', max_depth=max_depth, random_state=42)

    # Fit the model to the training data
    dt_classifier.fit(X_train, y_train)

    # Predict on the validation set
    y_pred = dt_classifier.predict(X_val)

    # Calculate the accuracy score
    accuracy = accuracy_score(y_val, y_pred)

    # Append the accuracy score to the list
    accuracy_scores.append(accuracy)

# Display the list of accuracy scores
print("Accuracy scores for each max_depth:", accuracy_scores)

# Create a figure and an axes object for the plot
fig, ax = plt.subplots(figsize=(10, 6))

# Plot the max_depth_values on the x-axis and the accuracy_scores on the y-axis
ax.plot(max_depth_values, accuracy_scores, marker='o')

# Label the x-axis and y-axis
ax.set_xlabel("Max Depth")
ax.set_ylabel("Accuracy Score")

# Add a title to the plot
ax.set_title("Decision Tree Accuracy vs. Max Depth on Validation Set")

# Set the x-axis ticks
ax.set_xticks(max_depth_values)

# Add a grid to the plot
ax.grid(True)

# Display the plot
plt.show()

# Combine the training and validation sets
X_train_val = pd.concat([X_train, X_val])
y_train_val = pd.concat([y_train, y_val])

# Display the shapes of the combined set
print("Combined training and validation set shape (X_train_val, y_train_val):", X_train_val.shape, y_train_val.shape)

from sklearn.metrics import classification_report
from sklearn.tree import DecisionTreeClassifier

# Instantiate a DecisionTreeClassifier with the optimal max_depth
final_dt_classifier = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=42)

# Fit the model to the combined training and validation data
final_dt_classifier.fit(X_train_val, y_train_val)

# Predict on the test set
y_test_pred_final = final_dt_classifier.predict(X_test)

# Generate and display the classification report
print("Classification Report on Test Set (Model trained on Train + Validation data):")
print(classification_report(y_test, y_test_pred_final))

from sklearn.tree import plot_tree

# Visualize the decision tree
plt.figure(figsize=(15, 10))
plot_tree(final_dt_classifier, feature_names=X_train_val.columns, class_names=final_dt_classifier.classes_, filled=True, rounded=True)
plt.show()